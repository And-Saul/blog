{
  "hash": "29f80c206628d575f22f75986f0808ad",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Implementing Bayesian Simple Linear Regression with Stan R\"\nauthor: \"Andrew Saul\"\ndate: \"2025-01-19\"\ncategories: [news, code, analysis]\nlightbox: true\nformat: \n  html:\n    code-fold: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rstan)\nlibrary(GGally)\nlibrary(bayesplot)\n```\n:::\n\n\n\n### Introduction\n\nThis is an instructional blog about creating a Markov Chain Monte Carlo (MCMC) linear regression model using Stan R. In order to keep things simple I decided to use only one explanatory variable in my model. The model was based on the relationship between height and weight of adults and data was generated using R software.\n\n#### Software preparation\n\nIt was essential that the Stan software package ran on my machine. Instructions how to do this are found [here](https://github.com/stan-dev/rstan/wiki/Rstan-Getting-Started). Through experience I found it necessary to ensure the latest version of R, Rtools and RStudio was loaded. This required the packages on my system being removed before the latest versions were installed.\n\n#### References\n\nRichard Mcelreath has illuminated the field of Bayesian Statistics to many through his excellent book [Statistical Rethinking](https://civil.colorado.edu/~balajir/CVEN6833/bayes-resources/RM-StatRethink-Bayes.pdf) and associated [youtube presentations of his course](https://www.youtube.com/watch?v=FdnMWdICdRs&list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus).\n\nThe \"Coding Club\" give a good step by step guide to implementing MCMC linear regression [here](https://ourcodingclub.github.io/tutorials/stan-intro/).\n\n<!-- During my statistical masters degree I found the subject of bayesian statistics complicated. However, shortly after completing the degree I discovered a gold mine of a resource about the subject, targeted at non-statisticians. The book is titled \"**Statistical Rethinking**\" by **Richard Mcelreath**. He has released multiple versions of his 20 week course on youtube \\[https://www.youtube.com/\\@rmcelreath\\] that is definitely worth a look. -->\n\n<!-- This blog will run through his course section on creating a generative simple linear regression model. -->\n\n<!-- Some terminology that Mcelreath uses in his lectures is as follows (https://bookdown.org/paul/applied-causal-analysis/estimator.html): -->\n\n<!-- -   Estimand: Parameter in the population which is to be estimated in a statistical analysis -->\n\n<!-- -   Estimator: A rule for calculating an estimate of a given quantity based on observed data -->\n\n<!--     -   Function of the observations, i.e., how observations are put together -->\n\n<!-- -   Estimation: - The process of finding an estimate, or approximation, which is a value that is usable for some purpose even if input data may be incomplete, uncertain, or unstable (value derived from the best information available) -->\n\n#### Investigating Relationships\n\nAccording to Mcelreath, before one implements linear regression, one should :\n\n1.  State the question they are investigating. In the example provided, the question would be \"What is the relationship between height and weight in the adult population?\". Therefore the parameters in the population (estimands) being estimated need to be defined. Here the estimands would be the y-intercept $\\alpha$ and the gradient $\\beta$ parameters describing the simple linear equation.\n2.  , Propose a scientific model by sketching the causal assumptions ie. the dependencies between the variables.\n3.  Check that the scientific model produces realistic results. Any code may have bugs. By creating synthetic data where the outcomes are known the validity of the model can be checked before being implemented on real data.\n\nThis blog will describe the process of creating a model for simulated height and weight measurements of adults. in R.\n\n### Generative model\n\nWeight (W) in kg can be considered as a proportion of height(H) in cm as well as being influenced by unobserved causes(U). This is summarised in the equation (@eq-Lin_Eq)\n\n$$\nW = \\beta*H - U\n$$ {#eq-Lin_Eq}\n\nGiven a vector of heights, the function to generate corresponding weights is as follows\n\n\n\n::: {.cell sim_echo='true'}\n\n```{.r .cell-code}\nsim_weight <- function(H,b,sd){\n  U <- rnorm(length(H), 0, sd)\n  W <- b*H +U\n}\n```\n:::\n\n\n\nAccording to our generative model, heights are linearly proportional to weights, with some noise due to the unobserved variables. Using the values b=0.5 and sd = 5, weights are calculated according to the above formula\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(25)\nN <- 20\nb <- 0.5\nsd <- 5\nH <- runif(N, 130, 190)\nW <- sim_weight(H, b, sd )\nHW_df <- tibble(Height = H, Weight = W)\n```\n:::\n\n\n\nThe resulting plot is seen in @fig-linPlot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(HW_df, aes(x= H, y = W))+\n  geom_point()+\n  labs(x = \"Height (cm)\",\n       y = \"Weight (kg)\")+\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Plot of generated points using sim_weight function](index_files/figure-html/fig-linPlot-1.png){#fig-linPlot width=672}\n:::\n:::\n\n\n\n#### Data Centring\n\nBayesian models require \"Prior\" distributions associated with each parameter. A prior acts as a regulariser to the observed data. We therefore need to have a ballpark idea as to observed distribution of each parameter. By centering the data on the mean height, the y-intercept term now represents the weight of a person of mean height.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nH_bar <- mean(H)\ncentred_H <- H-H_bar\ncentred_range <- range(centred_H)\nHW_df <- HW_df %>% bind_cols(centred_H = centred_H)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(HW_df, aes(x= centred_H, y = W))+\n  geom_point()+\n  labs(x = paste0(\"Height (from\", round(H_bar, 0),\" cm)\"),\n       y = \"Weight (kg)\")+\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Data that has been centred.](index_files/figure-html/fig-centred-1.png){#fig-centred width=672}\n:::\n:::\n\n\n\nFor comparison, parameters obtained using the frequentist linear regression are displayed below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_fit <- lm(W~centred_H, data = HW_df)\nsummary(lm_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = W ~ centred_H, data = HW_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.9546 -4.9650 -0.9118  3.8723 12.9614 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 79.25285    1.30692  60.641  < 2e-16 ***\ncentred_H    0.46496    0.07915   5.875 1.46e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.845 on 18 degrees of freedom\nMultiple R-squared:  0.6572,\tAdjusted R-squared:  0.6382 \nF-statistic: 34.51 on 1 and 18 DF,  p-value: 1.459e-05\n```\n\n\n:::\n:::\n\n\n\nFor the centred data, \\$\\alpha = \\$ 79.3, \\$\\beta = \\$ 0.46 and \\$\\sigma = \\$ 5.845\n\n#### Priors\n\nAs @fig-centred is centred, it is easier to estimate the prior distribution of $\\alpha$. This parameter should have a normal distribution centred on the mean weight of an individual of 160 cm. Since we know the linear model of height vs weight has a positive gradient a lognormal distribution can be used for $\\beta$. Mcelreath often uses an exponential model for the variance of the model. As we know that the standard deviation of simulations around the regression line is 5, we need to calculate the value of the exponential model parameter $\\lambda$. We know that $\\lambda$ is the inverse of its mean. On the conservative side, if we say the mean value of the variance is 10, then the value of $\\lambda$ should be set at 0.1.\n\nA bayesian model for the generated data is defined below\n\n$$\nW_i\\sim Normal(\\mu_i, \\sigma) \\\\\n\\mu_i = \\alpha + \\beta*(H_i - \\bar{H})  \\\\\n\\alpha \\sim Normal(75, 10) \\\\\n\\beta \\sim LogNormal(0,1) \\\\\n\\sigma \\sim Exp(0.1)\n$$\n\nOne question Mcelreath asks for any model is the about the accuracy of the priors.\n\n### Prior simulations\n\nin order to answer this question we need to perform prior prediction simulations. The code for $\\alpha$ and $\\beta$ simulations is displayed below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 1000\na <- rnorm(n, 75, 15)\nb <- rlnorm(n, 0, 1)\n```\n:::\n\n\n\nA plot of the prior predictive simulations is displayed in @fig-priorpred.\n\n\n\n::: {.cell fig-cation='Prior predictive simulations'}\n\n```{.r .cell-code}\nplot(NULL, xlim = c(-35, 35), ylim=c(-0, 150),\n     xlab= paste0(\"Centered Height (cm, 0 = \", round(H_bar, 0),\" cm)\"), \n                  ylab = \"Weight (kg)\")+\nfor (j in 1:50) abline(a=a[j], b=b[j])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ninteger(0)\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-priorpred-1.png){#fig-priorpred width=672}\n:::\n:::\n\n\n\nThe prior simulation demonstrates that at the centered value 0 $\\alpha$ is centred on around 75 kg and has a range of 40 to 90 kg. The $\\alpha$ prior is not so restrictive as to remove data from the generative model, but also not so loose as to permit extraordinary weight values in the model. Regarding $\\beta$ there are some relatively flat lines representing little change in weight with height. There are however some steep lines indicating unrealistic dramatic weight gain with height. The $\\beta$ prior could be tightened further as it appears quite weak. However, in linear regression a weak prior will have little effect on the model with increasing number of data points. The prior in effect acts as a single data point. For the sake of this exercise I will keep the priors as is.\n\nA note that prior settings are far more critical in non linear regression.\n\n#### Data\n\nData needs to be in list form for stan models.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_data <- list(\n  N = N,\n  x = centred_H,\n  y = W\n)\n```\n:::\n\n\n\n#### Model\n\nThe Stan code for the model is displayed below and written to a file. Within the code includes the definitions of the data, the parameters and the model. Generated quantities represent simulated data utilising the model. For assistance in writing Stan code, an AI engine such as ChatGPT can be used.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite(\"// Stan model with simulations for simple linear regression\n\ndata {\n  int<lower=0> N;          // Number of observations\n  vector[N] x;             // Predictor (height)\n  vector[N] y;             // Response (weight)\n\n}\n\nparameters {\n  real alpha;              // Intercept\n  real beta;               // Slope\n  real<lower=0> sigma;     // Standard deviation of the residuals\n}\n\nmodel {\n  // Priors\n  alpha ~ normal(75, 10);\n  beta ~ lognormal(0, 1);\n  sigma ~ exponential(0.1);    // Weakly informative prior for sigma\n\n  // Likelihood\n  y ~ normal( alpha + beta * x, sigma);\n}\n\n generated quantities {\n   vector[N] ysim;        // Predicted values\n\n   for (i in 1:N) {\n     ysim[i] = normal_rng(alpha + beta * x[i], sigma);\n   }    \n  }  // posterior distribution\",\n\n\"stan_model1.stan\")\n```\n:::\n\n\n\nThe command utilised to create the model is \"stan().\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_model <- \"stan_model1.stan\"\n\nfit <- stan(file = stan_model, data = stan_data, warmup = 500, iter = 1000, chains = 4, cores = 4, thin = 1, seed = 1234)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nhash mismatch so recompiling; make sure Stan code ends with a blank line\n```\n\n\n:::\n:::\n\n\n\nSummary statistics for the parameters is displayed below\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit, pars = c(\"alpha\", \"beta\", \"sigma\"))$summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            mean     se_mean         sd       2.5%       25%        50%\nalpha 79.1851986 0.036431290 1.40768527 76.4950297 78.312676 79.1883853\nbeta   0.4646649 0.002138231 0.08374583  0.3007056  0.407904  0.4638345\nsigma  6.1943126 0.032015679 1.15256463  4.4403892  5.420969  6.0047642\n            75%     97.5%    n_eff      Rhat\nalpha 80.079350 82.012210 1493.008 1.0003438\nbeta   0.518671  0.629741 1533.972 0.9993472\nsigma  6.789685  8.940377 1296.000 1.0001971\n```\n\n\n:::\n:::\n\n\n\nThe Rhat output for each parameter is close to 1. This indicates that the chains have converged.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntraceplot(fit)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n'pars' not specified. Showing first 10 parameters by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/traceplot-1.png){width=672}\n:::\n:::\n\n\n\nWith the overlapping of chains, the traceplots confirm the conclusion of the Rhat values ie. all chains converged. Note that this version of traceplot does not contain the warmup period.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\njoint_post_table <- rstan::extract(fit) \n```\n:::\n\n\n\nThe joint posterior predictive distribution data is extracted utilising the \"rstan::extract(fit)\" code. The namespace stan:: must be used as there is a conflict with the extract function. In @fig-corr there are correlation plots between the three parameters of the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\njoint_post_table[1:3] %>% \n  pairs()\n```\n\n::: {.cell-output-display}\n![Correlation plots between the parameters of the linear model](index_files/figure-html/fig-corr-1.png){#fig-corr width=672}\n:::\n:::\n\n\n\nBecause the data is centred, there should be no correlation between $\\alpha$ and $\\beta$ parameters. Additionally, no correlation should exist between $\\sigma$ and the other parameters. The lack of correlations is displayed in @fig-corr.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nma <- mean(joint_post_table$alpha)\nmb <- mean(joint_post_table$beta)\nmsig <- mean(joint_post_table$sigma)\n\nxr <- seq(-25,25,1)\nyCI <- map(xr, ~quantile(joint_post_table$alpha +joint_post_table$beta * .x, probs = c(0.05, 0.95))) %>% \n  bind_rows()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxr <- seq(-25,30,1)\nyCI <- map(xr, ~quantile(joint_post_table$alpha +joint_post_table$beta * .x, probs = c(0.05, 0.95))) %>% \n  bind_rows()\n\nggplot(stan_data %>% as_tibble)+\n  geom_point(aes(x=x, y = y))+\n  geom_abline(aes(slope = beta, intercept = alpha), alpha=0.05,\n              data = joint_post_table[1:3] %>% as_tibble())+\n  geom_abline(slope = mb, intercept = ma, color = \"red\", alpha = 0.5, linewidth = 1,\n              data = joint_post_table[1:3] %>% as_tibble())+\n  geom_line(data = yCI, aes(x = xr, y = `5%`, color='red'), linewidth = 1)+\n  geom_line(data = yCI, aes(x = xr, y = `95%`, color='red'), linewidth = 1)+\n  theme_bw()+\n  labs(x = \"Centred Height (cm, 0 = 160 cm)\",\n       y = \"Weight (kg)\",\n       title = \"Distribution of 2000 mu samples with the mean and 90% credible interval\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `geom_abline()`: Ignoring `data` because `slope` and/or `intercept` were\nprovided.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![2000 draws from the posterior distribution for alpha and beta, and the mean and 90% credible interval](index_files/figure-html/fig-postlinedraws-1.png){#fig-postlinedraws width=672}\n:::\n:::\n\n\n\n@fig-postlinedraws displays all the posterior distribution draws for $\\alpha$ and $\\beta$ in the form of lines. In addition @fig-postlinedraws demonstrates the 90% credible intervals of the posterior draws that form $\\mu$. 90% was chosen due to computational stability and relation to Type-S errors [see here](https://mc-stan.org/rstanarm/reference/posterior_interval.stanreg.html)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  5% & 95% credible intervals\nxr <- seq(-25,25,1)\nyCI <- map(xr, ~quantile(joint_post_table$alpha +joint_post_table$beta * .x, probs = c(0.05, 0.95))) %>% \n  bind_rows()\n\nas_tibble(stan_data) %>% \nggplot(aes(x=centred_H, y=W))+\n  geom_point()+\n  geom_abline(slope = mb, intercept = ma, color = \"black\")+\n  geom_line(data = yCI, aes(x = xr, y = `5%`, color='red'))+\n  geom_line(data = yCI, aes(x = xr, y = `95%`, color='red'))+\n  guides(color = \"none\")+\n  theme_bw()+\n  labs(x = \"Centred Height (cm, 0 = 160 cm)\",\n       title = \"5% & 95% Credible Intervals (red) and mean regression line \\nobtained from draws of alpha and beta posterior distributions\"\n       )\n```\n\n::: {.cell-output-display}\n![90% credible intervals for the posterior line draws. ](index_files/figure-html/fig-ci-1.png){#fig-ci width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(joint_post_table[1:3])\n```\n\n::: {.cell-output-display}\n![Pairs Plot. As data is centred, there should not be any correlation between alpha and beta.](index_files/figure-html/fig-pairs-1.png){#fig-pairs width=672}\n:::\n:::\n\n\n\nA pairs plot of the parameters is seen in @fig-pairs. One can see that no correlation exists between $\\alpha$ and $\\beta$. This is expected when the explanatory variable is centred.\n\n#### Parameter summaries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1,3))\n\nplot(density(joint_post_table$alpha), main = \"Alpha\")\nabline(v =summary(lm_fit)$coefficients[1], col = 4, lty = 2)\n\nplot(density(joint_post_table$beta), main = \"Beta\")\nabline(v = summary(lm_fit)$coefficients[2], col = 4, lty = 2)\n\nplot(density(joint_post_table$sigma), main = \"Sigma\")\nabline(v = sigma(lm_fit), col = 4, lty = 2)\n```\n\n::: {.cell-output-display}\n![The peak of each marginal distribution matches the Maximum Likelihood Estimation (MLE) from the frequentist model](index_files/figure-html/fig-margdist-1.png){#fig-margdist width=672}\n:::\n:::\n\n\n\nOne can see from @fig-margdist that the mean marginal posterior distribution of each parameter matches its Maximum Likelihood Estimation (MLE) in the frequentist model.\n\nUseful functions to plot the marginal parameter distributions and histograms is stan_dens() and stan_hist() respectively\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_dens(fit, pars = c(\"alpha\", \"beta\", \"sigma\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nstan_hist(fit, pars = c(\"alpha\", \"beta\", \"sigma\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n\n\nIn @fig-ci90, the mean marginal parameter estimates are displayed with their associated 90% credible intervals. It is difficult to see the credible intervals, especially for $\\beta$ and $\\sigma$, because the scale of the parameters is different. This plot is useful if all points are scaled.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit, , pars = c(\"alpha\", \"beta\", \"sigma\"), show_density = FALSE, ci_level = 0.5, outer_level = 0.90, fill_color = \"salmon\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nci_level: 0.5 (50% intervals)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nouter_level: 0.9 (90% intervals)\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Mean parameter estimates with their 90% Credible Intervals](index_files/figure-html/fig-ci90-1.png){#fig-ci90 width=672}\n:::\n:::\n\n\n\n#### Extracting the y Predictions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny_rep <- as.matrix(fit, pars = \"ysim\")\ndim(y_rep)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2000   20\n```\n\n\n:::\n:::\n\n\n\nIn @fig-overlay, each light-blue line is a density plot created by simulating y values from a single draw of parameters from the posterior density distribution for each of the twenty x value data points. Five hundred iterations of simulations (light-blue density plots) are displayed, overlay-ed by the density plot for the y value datapoints (dark blue line). It is clear that the density plot of the observed values is contained well-within the range of density plots generated from the posterior distribution.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nppc_dens_overlay(W, y_rep[1:500, ])\n```\n\n::: {.cell-output-display}\n![density distribution of simulated y values using parameter values drawn from the posterior denstiy distribution](index_files/figure-html/fig-overlay-1.png){#fig-overlay width=672}\n:::\n:::\n\n\n\nThe mean of each distribution can be plotted and compared to the mean of the observed values, as seen in @fig-meanhist\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nppc_stat(y = W, yrep = y_rep, stat = \"mean\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Histogram of mean value for each simulated distribution (y_rep) compared to the mean value of the generated distribution (y)](index_files/figure-html/fig-meanhist-1.png){#fig-meanhist width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}